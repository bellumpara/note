{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The demo for the scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_valitaion  交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.9,  3. ,  1.4,  0.2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用train_test_split来分出训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (90,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size= 0.4, random_state = 0)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel= 'linear', C= 1).fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score是用来评判这个模型的好坏，即在测试集中的正确率\n",
    "\n",
    "下面提到交叉验证。**它也只是一种判断模型好坏的方法。**\n",
    "\n",
    "运用它的目的和原因：\n",
    "①避免了数据量过少的麻烦\n",
    "②避免了人为的过拟合\n",
    "有数据d，经过k次平均分割，每次分割成traini和testi分别代表第i个测试集合训练集，用traini训练模型，并用testi测试模型，得到的第i个模型的得分是scorei，当结果k次执行后，共得到k个得分[score1,score2,⋯,scorek]，求这k个得分的平均值作为模型的最终得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  1.        ,  0.96666667,  0.96666667,  1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv = 5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的参数（训练模型，特征数据，目标数据，折叠交叉次数5次即验证5次），\n",
    "然后输出平均分数和具有95%置信区间的分数估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    ">cross_validation.cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, >verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
    ">cross_val_score的所有参数，score=可以用来改变计分方式，比如加权score='f1_weight'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing 数据标准化模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **将数据转化为标准正态分布**\n",
    "  preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n",
    "  两种实现方式：\n",
    "    x_scale = preprocessing.scale(x)\n",
    "    scaler = preprocessing.StandarScaler()\n",
    "    x_scaled = scaled.fit_transform(x)\n",
    "\n",
    "  \n",
    "2. **将特征取值缩小到一个范围（如0到1）**\n",
    "  方法目的：①对于方差非常小的属性可以增强其稳定性\n",
    "  ②维持稀疏矩阵中为0的条目\n",
    "\n",
    "  preprocessing.minmax_scale(X, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "  或者\n",
    "  min_max_scaler = preprocessing.MinMaxScaler()\n",
    "  X_minMax = min_max_scaler.fit_transform(X)\n",
    "  \n",
    "  \n",
    "3. **正则化，归一化**\n",
    "  preprocessing.normalize(X, norm='l2', axis=1, copy=True)\n",
    "  norm可取值 'l1', 'l2', 'max'\n",
    "\n",
    "  或者\n",
    "  normalizer = preprocessing.Normalizer().fit(X)\n",
    "  normalizer.transform(X)\n",
    "  fit的过程并没有做什么，知道使用属性transform才使得数据变形\n",
    "  \n",
    "  \n",
    "4. **二值化**\n",
    "  preprocessing.binarize(X, threshold=0.0, copy=True)\n",
    "  threshold为阈值，小于等于threshold为0，大于的为1\n",
    "\n",
    "  binarizer = preprocessing.Binarizer(threshold=1.1)\n",
    "  binarizer.transform(X)\n",
    "  \n",
    "  \n",
    "5. **数据缺失**\n",
    "  class preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0,   copy=True)\n",
    "  这是一个类，上面的有er的也都是类，赋值到一个对象上后，可以用它自身的方法\n",
    "  参数： \n",
    "  •missing_values：int 或者 “NaN”，对np.nan的值用 \"NaN\"\n",
    "  •strategy：\"mean\"、\"median\"、\"most_frequent\"\n",
    "  属性： \n",
    "  •statistics_：ndarray，当axis==0时，取每列填补时用的值\n",
    "  方法：fit(X[, y])、transform(X[, y, copy])、fit_transform(X[, y])、get_params([deep])、   set_params(**params)\n",
    "  \n",
    "  \n",
    "6. **生成多维特征**\n",
    "可以将数据多项式结合生成多维特征，比如 [a, b] 的二次多项式特征为 [1, a, b, a^2, ab, b^2]\n",
    "\n",
    "•class preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)：\n",
    "参数： \n",
    "•degree：int，多项式次数\n",
    "•interaction_only：boolean，是否只产生交叉相乘的特征\n",
    "•include_bias：boolean，是否包含偏移列，即全为 1 的列\n",
    "属性： \n",
    "•powers_：ndarray，二维数组。powers_[i, j] 表示第 i 维输出中包含的第 j 维输入的次数\n",
    "•n_input_features_：int，输入维数\n",
    "•n_output_features_：int，输出维数\n",
    "方法：fit(X[, y])、transform(X[, y, copy])、fit_transform(X[, y])、get_params([deep])、set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_transformed = scaler.transform(x_train)\n",
    "clf = svm.SVC(C=1).fit(x_train_transformed, y_train)\n",
    "x_test_transformed = scaler.transform(x_test)\n",
    "clf.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
